import os
from google import genai
import streamlit as st
from dotenv import load_dotenv
# from google.genai import types


load_dotenv()  
API_KEY = os.getenv("GOOGLE_API_KEY")

client = genai.Client(api_key=API_KEY) 
# model_name = "gemini-1.5-flash-001-tuning"

# for model_info in client.models.list():
#     print(model_info.name)

# create tuning model
# training_dataset =  [
#     ["Â¿CÃ³mo diferencio el corte juliana del brunoise?", "ğŸ¥• Juliana: tiras finas y largas. ğŸ”ª Brunoise: cubos pequeÃ±os."],
#     ["Â¿CÃ³mo hacer un roux sin grumos?", "ğŸ Derrite mantequilla, agrega harina y remueve constantemente."],
#     ["Â¿Por quÃ© es importante la mise en place?", "ğŸ½ï¸ Tener todo listo antes de cocinar ahorra tiempo y evita errores."],
#     ["Â¿QuÃ© mÃ©todos de cocciÃ³n existen?", "ğŸ”¥ Hervido, asado, frito, al vapor, salteadoâ€¦ Â¡Cada tÃ©cnica cambia el sabor!"],
#     ["Â¿CÃ³mo evitar que los huevos revueltos queden gomosos?", "ğŸ³ Usa fuego bajo, remueve con suavidad y retira antes de que se sequen."],
#     ["Â¿Por quÃ© la sal es importante en panaderÃ­a?", "ğŸ¥– Controla la fermentaciÃ³n, mejora el sabor y da estructura."],
#     ["Â¿CÃ³mo recuperar una mayonesa cortada?", "ğŸ¥š Agrega una yema extra y emulsiona poco a poco. Â¡Magia! âœ¨"],
#     ["Â¿CÃ³mo saber si un filete estÃ¡ en su punto sin termÃ³metro?", "ğŸ¥© Usa la prueba del tacto con la mano. (Tierno = rojo, firme = bien cocido)."],
#     ["Â¿CÃ³mo lograr una pasta cremosa sin crema?", "ğŸ Usa agua de cocciÃ³n, queso ğŸ§€ y mantequilla ğŸ§ˆ para una salsa sedosa."],
#     ["Â¿QuÃ© cortes de carne son mejores para estofar? ", "ğŸ„ Osobuco, falda, carrillera, pecho. MÃ¡s colÃ¡geno = mÃ¡s jugosidad."],
#     ["Â¿CÃ³mo hacer una bechamel sin grumos?", "ğŸ¥› Agrega la leche caliente poco a poco mientras bates con energÃ­a."],
#     ["Â¿Diferencia entre levadura fresca y seca?", "ğŸ Fresca = mÃ¡s humedad. ğŸŒ¾ Seca = concentrada y dura mÃ¡s tiempo."],
#     ["Â¿CÃ³mo evitar que el arroz quede pastoso?", "ğŸš LÃ¡valo bien antes de cocinar y usa la proporciÃ³n correcta de agua."],
#     ["Â¿Por quÃ© mi bizcocho no sube?", "ğŸ‚ Puede ser por levadura vieja, horno frÃ­o o abrir la puerta antes de tiempo."],
#     ["Â¿CuÃ¡nto tiempo debe reposar la carne despuÃ©s de cocinarla?", "ğŸ¥© De 5 a 10 minutos para que los jugos se redistribuyan."],
# ]
# training_dataset=types.TuningDataset(
#         examples=[
#             types.TuningExample(
#                 text_input=i,
#                 output=o,
#             )
#             for i,o in training_dataset
#         ],
#     )
# tuning_job = client.tunings.tune(
#     base_model='models/gemini-1.5-flash-001-tuning',
#     training_dataset=training_dataset,
#     config=types.CreateTuningJobConfig(
#         epoch_count= 5,
#         batch_size=4,
#         learning_rate=0.001,
#         tuned_model_display_name="gastronomic-assistant"
#     )
# )

# # generate content with the tuned model
# response = client.models.generate_content(
#     model=tuning_job.tuned_model.model,
#     contents='Â¿Por quÃ© mi bizcocho no sube?',
# )

# # generate content with the tuned model
# response = client.models.generate_content(
#     model="tunedModels/asistente-de-gastronomia-6aszd436vezn",
#     contents='Â¿Por quÃ© mi bizcocho no sube?',
# )

# print(response.text)



model_name = "tunedModels/asistente-de-gastronomia-6aszd436vezn"

st.set_page_config(page_title="Asistente gastronÃ³mico", page_icon="ğŸ”")

st.title("Asistente gastronÃ³mico ğŸ‘¨ğŸ½â€ğŸ³ğŸ¤–ğŸ”")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

if prompt := st.chat_input("Escribe tu mensaje aqui"):
    with st.chat_message("user"):
        st.markdown(f"Yo: {prompt}")
    st.session_state.messages.append({"role": "user", "content": prompt})

    responseFromGemini =  client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        
    response = f"Gastro-bot: {responseFromGemini.candidates[0].content.parts[0].text}"

    with st.chat_message("assistant"):
        st.markdown(response)
        
    st.session_state.messages.append({"role": "assistant", "content": response})